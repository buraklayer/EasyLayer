{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b809bc47-5fbd-4725-a73e-cedfa3fd1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d76d9687-8ebc-43bd-ac59-95de86f16350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_orders_table() -> Any:\n",
    "    \n",
    "    # Read the csv file\n",
    "    orders_df = pd.read_csv(\"/Users/burakozen/Jupyter_Projects/data/olist_orders_dataset.csv\")\n",
    "\n",
    "    # Converting object types to datetime for further analysis\n",
    "    orders_df.order_purchase_timestamp = pd.to_datetime(orders_df.order_purchase_timestamp)\n",
    "    orders_df.order_approved_at = pd.to_datetime(orders_df.order_approved_at)\n",
    "    orders_df.order_delivered_carrier_date = pd.to_datetime(orders_df.order_delivered_carrier_date)\n",
    "    orders_df.order_delivered_customer_date = pd.to_datetime(orders_df.order_delivered_customer_date)\n",
    "    orders_df.order_estimated_delivery_date = pd.to_datetime(orders_df.order_estimated_delivery_date)\n",
    "\n",
    "    # Important Data Info \n",
    "    print(\"All order_ids are unique:\",orders_df.customer_id.nunique()==len(orders_df))\n",
    "    print(\"Max order purchase date:\", orders_df.order_purchase_timestamp.max())\n",
    "    print(\"Min order pruchase date:\", orders_df.order_purchase_timestamp.min())\n",
    "    print(\"Different order statuses:\", orders_df.order_status.unique())\n",
    "    \n",
    "    return orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d965ab46-09ae-429a-aa63-7dc72ff59b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_payments_table() -> Any:\n",
    "    \n",
    "    # Read the csv file\n",
    "    payments_df = pd.read_csv(\"/Users/burakozen/Jupyter_Projects/data/olist_order_payments_dataset.csv\")\n",
    "    \n",
    "    # Important Data Info\n",
    "    print(\"Total number of rows:\",len(payments_df))\n",
    "    print(\"Total number of unique orders:\",payments_df.order_id.nunique())\n",
    "    print(\"Payment Types:\", payments_df.payment_type.unique())\n",
    "    print(\"Payment Value Mean:\", payments_df.payment_value.mean())\n",
    "    \n",
    "    return payments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a8661b1-5f51-4f43-97e6-fe332c98c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_customers_table() -> Any:\n",
    "    \n",
    "    # Read the csv file\n",
    "    customers_df = pd.read_csv(\"/Users/burakozen/Jupyter_Projects/data/olist_customers_dataset.csv\")\n",
    "    \n",
    "    # Important Data Info\n",
    "    print(\"Total number of customers:\", customers_df.customer_unique_id.nunique())\n",
    "    print(\"Total number of different cities:\", customers_df.customer_city.nunique())\n",
    "    print(\"Total number of different states:\", customers_df.customer_state.nunique())\n",
    "    \n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09ca20b5-dc15-436b-9fdf-a8ae9c8dab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orders_general_features(orders_df) -> Any:\n",
    "    \n",
    "    # ORDER TABLE BASED FEATURE EXTRACTION - ORDER FEATURES\n",
    "\n",
    "    # Drop rows which has NA values in the timestamp columns\n",
    "    orders_df = orders_df[orders_df['order_approved_at'].notna() \n",
    "                          & orders_df['order_purchase_timestamp'].notna() \n",
    "                          & orders_df['order_delivered_carrier_date'].notna() \n",
    "                          & orders_df['order_approved_at'].notna()\n",
    "                          & orders_df['order_estimated_delivery_date'].notna() \n",
    "                          & orders_df['order_delivered_customer_date'].notna()]\n",
    "\n",
    "\n",
    "    # Data Sanity Check\n",
    "    orders_df = orders_df.loc[~((orders_df['order_approved_at'] < orders_df['order_purchase_timestamp']) | (orders_df['order_delivered_carrier_date'] < orders_df['order_approved_at'])),:]\n",
    "\n",
    "    # Computing new features: total_waiting & days_between_estimate_actual_delivery\n",
    "    orders_df[\"payment_approvement_waiting\"]=(orders_df.order_approved_at - orders_df.order_purchase_timestamp).dt.days\n",
    "    orders_df[\"delivered_carrier_waiting\"]=(orders_df.order_delivered_carrier_date - orders_df.order_approved_at).dt.days\n",
    "    orders_df[\"total_waiting\"] = orders_df.payment_approvement_waiting + orders_df.delivered_carrier_waiting\n",
    "    orders_df[\"days_between_estimate_actual_delivery\"]=(orders_df.order_estimated_delivery_date - orders_df.order_delivered_customer_date).dt.days\n",
    "\n",
    "    # Select features to be returned\n",
    "    orders_general_features=orders_df[['order_id','order_status','total_waiting','days_between_estimate_actual_delivery']]\n",
    "    \n",
    "    # Important Data Info\n",
    "    print(\"All total_waiting values non-negative:\", (orders_general_features.total_waiting>=0).all())\n",
    "    print(\"Max of days between estimate and actual delivery:\", orders_general_features.days_between_estimate_actual_delivery.max())\n",
    "    print(\"Min of days between estimate and actual delivery:\", orders_general_features.days_between_estimate_actual_delivery.min())\n",
    "    \n",
    "    return orders_general_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44f3147b-8703-4368-a79d-cbcb9b183fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orders_payments_features(payments_df) -> Any:\n",
    "    \n",
    "    # PAYMENT TABLE BASED FEATURE EXTRACTION - ORDER FEATURES\n",
    "\n",
    "    # Drop rows which has NA values in the timestamp columns\n",
    "    payments_df = payments_df[payments_df['payment_type'].notna() & payments_df['payment_value'].notna()] \n",
    "\n",
    "\n",
    "    # Computing new features: use_voucher & total_payment & payment_type\n",
    "    payments_df_agg=payments_df\\\n",
    "    .assign(is_voucher= np.where(payments_df['payment_type']=='voucher',1,0))\\\n",
    "    .groupby(['order_id'],as_index=False) \\\n",
    "    .agg(use_voucher=(\"is_voucher\",\"max\"), \\\n",
    "         total_payment=(\"payment_value\",\"sum\"), \\\n",
    "         payment_type=(\"payment_type\",\"max\") \\\n",
    "        )\n",
    "\n",
    "    # Select columns to be returned\n",
    "    orders_payments_features=payments_df_agg[['order_id','use_voucher','total_payment','payment_type']]\n",
    "\n",
    "    # Important Data Info\n",
    "    print(\"All total_payment values non-negative:\", (orders_payments_features.total_payment>=0).all())\n",
    "    \n",
    "    return orders_payments_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0cd16208-4662-4e5f-969e-683c3ec238a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_customer_features(customers_df) -> Any:\n",
    "    \n",
    "    # CUSTOMER TABLE BASED FEATURE EXTRACTION - CUSTOMER FEATURES\n",
    "\n",
    "    # Merge 2 dataframes\n",
    "    orders_customers_merged = orders_df.merge(customers_df,left_on='customer_id',right_on='customer_id',how='left')\n",
    "\n",
    "    # Compute a new feature: multiple_order\n",
    "    orders_customers_merged[\"total_orders\"]=orders_customers_merged.groupby('customer_unique_id')['customer_id'].transform('count')\n",
    "    orders_customers_merged['multiple_order'] = np.where(orders_customers_merged['total_orders']> 1, 1, 0)\n",
    "\n",
    "    #Compute a new feature: days_since_order\n",
    "    dataset_max_date=orders_customers_merged.order_purchase_timestamp.max()\n",
    "    orders_customers_merged['days_since_order'] = (dataset_max_date-orders_customers_merged.order_purchase_timestamp).dt.days\n",
    "\n",
    "    # Filter out only the first orders of users in the dataset\n",
    "    orders_customers_merged[\"order_rank\"]=orders_customers_merged.groupby('customer_unique_id')['order_purchase_timestamp'].rank(method='first')\n",
    "    orders_customers_merged=orders_customers_merged[orders_customers_merged[\"order_rank\"]==1.0].drop(columns=['order_rank'])\n",
    "\n",
    "    # Select columns to be returned and rename them accordingly\n",
    "    orders_customers_merged = orders_customers_merged.rename(columns={\"order_id\": \"first_order_id\", \"days_since_order\": \"days_since_first_order\"})\n",
    "    customer_features = orders_customers_merged[['customer_unique_id','customer_city','customer_state','first_order_id','days_since_first_order','multiple_order']]\n",
    "\n",
    "    # Important Data Info\n",
    "    print(\"Ratio of multiple-orders customers over single-order customers:\",round(customer_features.multiple_order.value_counts()[1]/customer_features.multiple_order.value_counts()[0],2))\n",
    "\n",
    "    return customer_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d11c2d0-c027-4856-b35e-dfd4f837c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(orders_general_features, orders_payments_features, customer_features) -> Any:\n",
    "\n",
    "    # TRAINING DATA GENERATION\n",
    "\n",
    "    # Merge dataframes and drop irrelevant columns \n",
    "    order_features = orders_general_features.merge(orders_payments_features,left_on='order_id',right_on='order_id',how='left')\n",
    "    training_data_raw = customer_features.merge(order_features,left_on='first_order_id',right_on='order_id',how='left').drop(columns=['order_id','order_status'])\n",
    "\n",
    "    # Rename columns\n",
    "    training_data_raw = training_data_raw.rename(columns={\n",
    "                                      \"total_waiting\": \"first_order_total_waiting\", \n",
    "                                      \"days_between_estimate_actual_delivery\": \"first_order_days_between_estimate_actual_delivery\",\n",
    "                                      \"use_voucher\": \"first_order_use_voucher\",\n",
    "                                      \"total_payment\": \"first_order_total_payment\",\n",
    "                                      \"payment_type\": \"first_order_payment_type\"\n",
    "                                     })\n",
    "\n",
    "    # Decrease number of dimensions in the customer_city and customer_state columns to 6 (before applyling one-hot-encoding)\n",
    "    top5_cities = [\"sao paulo\",\"rio de janeiro\",\"belo horizonte\",\"brasilia\",\"curitiba\"]\n",
    "    top5_states = [\"SP\",\"RJ\",\"MG\",\"RS\",\"PR\"]\n",
    "    training_data_raw['customer_city'] = training_data_raw['customer_city'].apply(lambda city: city if city in top5_cities else 'other')\n",
    "    training_data_raw['customer_state'] = training_data_raw['customer_state'].apply(lambda state: state if state in top5_states else 'other')\n",
    "\n",
    "    # Create a label column 'churned': If multiple_order is 1, then CHURNED=0, otherwise CHURNED=1. Select only the churned customers if it has been more than 365 days since the first order\n",
    "    training_data_raw['churned'] = 1 \n",
    "    training_data_raw.loc[training_data_raw.multiple_order == 1, 'churned'] = 0\n",
    "    training_data_raw = training_data_raw.loc[ (training_data_raw.churned==0) | ((training_data_raw.churned==1) & (training_data_raw.days_since_first_order > 365))]\n",
    "\n",
    "    #Select columns to be returned and drop NA rows\n",
    "    training_data = training_data_raw.drop(columns=['multiple_order']).dropna()\n",
    "    \n",
    "    # Important Data Info\n",
    "    print(\"Number of training data records:\", len(training_data))\n",
    "    print(\"Churn user ratio after first order:\", round(training_data.churned.value_counts()[1]/len(training_data),2))\n",
    "\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd343a35-b95c-494f-89da-8bb0886c1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_churn_model(training_data) -> Any:\n",
    "    \n",
    "    # Parameters for data split\n",
    "    test_size_fraction = 0.33\n",
    "    random_seed = 42\n",
    "\n",
    "    # Data Split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(training_data.drop(columns=['customer_unique_id','first_order_id','churned']),\n",
    "                                                        training_data.churned,\n",
    "                                                        test_size=test_size_fraction,\n",
    "                                                        random_state=random_seed)\n",
    "\n",
    "    # Define a One-Hot Encoder Transformer\n",
    "    categorical_cols = ['customer_city','customer_state','first_order_payment_type']\n",
    "    transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],remainder='passthrough')\n",
    "    \n",
    "    \n",
    "    # Model: Define a Gradient Boosting Classifier\n",
    "    learning_rate = 0.01\n",
    "    max_depth = 6\n",
    "    max_features = 'sqrt'\n",
    "    min_samples_leaf = 10\n",
    "    n_estimators = 100\n",
    "    subsample = 0.8\n",
    "    random_state = 42\n",
    "    \n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                       max_depth=max_depth,\n",
    "                                       max_features=max_features,\n",
    "                                       min_samples_leaf=min_samples_leaf,\n",
    "                                       n_estimators=n_estimators,\n",
    "                                       subsample=subsample,\n",
    "                                       random_state=random_state)\n",
    "\n",
    "    # Pipeline Fit\n",
    "    pipeline = Pipeline(steps=[('t', transformer), ('m', model)])\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "\n",
    "    # Model Evaluation\n",
    "    # 1. Predict probabilities of target 1:Churned\n",
    "    probs = pipeline.predict_proba(X_test)[:,1]\n",
    "    # 2. Calculate average precision and area under the receiver operating characteric curve (ROC AUC)\n",
    "    avg_precision = average_precision_score(Y_test, probs, pos_label=1)\n",
    "    auc = roc_auc_score(Y_test, probs)\n",
    "\n",
    "    # Important Model Metrics\n",
    "    print(\"Average Precision Value:\",avg_precision)\n",
    "    print(\"Area under ROC:\",auc)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f39bbe4b-0547-43d7-b3c6-7a65947ed951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- read_orders_table starts ---\n",
      "All order_ids are unique: True\n",
      "Max order purchase date: 2018-10-17 17:30:18\n",
      "Min order pruchase date: 2016-09-04 21:15:19\n",
      "Different order statuses: ['delivered' 'invoiced' 'shipped' 'processing' 'unavailable' 'canceled'\n",
      " 'created' 'approved']\n",
      "--- read_orders_table ends ---\n",
      "\n",
      "--- read_payments_table starts ---\n",
      "Total number of rows: 103886\n",
      "Total number of unique orders: 99440\n",
      "Payment Types: ['credit_card' 'boleto' 'voucher' 'debit_card' 'not_defined']\n",
      "Payment Value Mean: 154.10038041699553\n",
      "--- read_payments_table ends ---\n",
      "\n",
      "--- read_customers_table starts ---\n",
      "Total number of customers: 96096\n",
      "Total number of different cities: 4119\n",
      "Total number of different states: 27\n",
      "--- read_customers_table ends ---\n",
      "\n",
      "--- extract_orders_general_features starts ---\n",
      "All total_waiting values non-negative: True\n",
      "Max of days between estimate and actual delivery: 146\n",
      "Min of days between estimate and actual delivery: -189\n",
      "--- extract_orders_general_features ends---\n",
      "\n",
      "--- extract_orders_payments_features starts ---\n",
      "All total_payment values non-negative: True\n",
      "--- extract_orders_payments_features ends ---\n",
      "\n",
      "--- extract_customer_features starts ---\n",
      "Ratio of multiple-orders customers over single-order customers: 0.03\n",
      "--- extract_customer_features ends ---\n",
      "\n",
      "--- generate_training_data starts ---\n",
      "Number of training data records: 29221\n",
      "Churn user ratio after first order: 0.9\n",
      "--- generate_training_data ends ---\n",
      "\n",
      "--- train_churn_model starts ---\n",
      "Average Precision Value: 0.9584324018084007\n",
      "Area under ROC: 0.7898759194173129\n",
      "--- train_churn_model ends ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- read_orders_table starts ---\")\n",
    "orders_df = read_orders_table()\n",
    "print(\"--- read_orders_table ends ---\")\n",
    "\n",
    "print(\"\\n--- read_payments_table starts ---\")\n",
    "payments_df = read_payments_table()\n",
    "print(\"--- read_payments_table ends ---\")\n",
    "\n",
    "print(\"\\n--- read_customers_table starts ---\")\n",
    "customers_df = read_customers_table()\n",
    "print(\"--- read_customers_table ends ---\")\n",
    "\n",
    "print(\"\\n--- extract_orders_general_features starts ---\")\n",
    "orders_general_features  = extract_orders_general_features(orders_df)\n",
    "print(\"--- extract_orders_general_features ends---\")\n",
    "\n",
    "print(\"\\n--- extract_orders_payments_features starts ---\")\n",
    "orders_payments_features = extract_orders_payments_features(payments_df)\n",
    "print(\"--- extract_orders_payments_features ends ---\")\n",
    "\n",
    "print(\"\\n--- extract_customer_features starts ---\")\n",
    "customer_features = extract_customer_features(customers_df)\n",
    "print(\"--- extract_customer_features ends ---\")\n",
    "\n",
    "print(\"\\n--- generate_training_data starts ---\")\n",
    "training_data = generate_training_data(orders_general_features,orders_payments_features,customer_features)\n",
    "print(\"--- generate_training_data ends ---\")\n",
    "\n",
    "print(\"\\n--- train_churn_model starts ---\")\n",
    "churn_model = train_churn_model(training_data)\n",
    "print(\"--- train_churn_model ends ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
